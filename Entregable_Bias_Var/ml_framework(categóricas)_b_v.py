# -*- coding: utf-8 -*-
"""ML_Framework(Categóricas)_B_V.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XfU6FI83BX2wBtD3Fj8qw4malg-bRvLf

### Uso de framework de ML para la implementación de una solución en un dataset de variables categóricas

Primeramente importamos las librerías necesarias para la implementación del modelo
"""

# Commented out IPython magic to ensure Python compatibility.
# Análisis de datos
import pandas as pd
import numpy as np
import random as rnd  


# Visualización 
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

url = 'https://raw.githubusercontent.com/IsaacE12/ML/master/Entregable_Bias_Var/weatherAUS.csv'
df = pd.read_csv(url) 
df.shape  
df.head

"""Quitamos las columnas que son innecesarias para nuestra predicción"""

data = df.drop(columns=['Evaporation','Sunshine','Cloud3pm','Cloud9am','Date','Location']) 
data = data.dropna(how='any') 
data 
print(data.shape)

"""Se remplazan los "No" y los "Si" en las variables de RainToday y RainTomorrow"""

data['RainToday'].replace({'No':0, 'Yes':1}, inplace = True) 
data['RainTomorrow'].replace({'No':0, 'Yes':1}, inplace = True)

"""Se hace uso de las variables dummy's para el reordenamiento de las variables categóricas"""

Categoricas = ['WindGustDir', 'WindDir3pm', 'WindDir9am']
dff = pd.get_dummies(data, columns=Categoricas)  
print(dff.shape)
dff.head()

"""### Se obtiene la matriz de correlación y se eliminan las variables que tienen menos de 0.5 de correlación respecto a la variable que nos interesa"""

# Calculate the correlation matrix
corr = dff.corr()
corr_1 = pd.DataFrame(abs(corr['RainTomorrow']),columns = ['RainTomorrow'])
nonvals = corr_1.loc[corr_1['RainTomorrow'] < 0.005]
print('Var correlation < 0.5%',nonvals)
nonvals = list(nonvals.index.values)

from sklearn.model_selection import train_test_split
Y = dff['RainTomorrow']
X = dff.drop(columns=['RainTomorrow']) 
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=5)

"""### Se aplica la clasificación de RandomForest"""

# Se importa la librería y se definde el model
from sklearn.ensemble import RandomForestClassifier  
RandomForest = RandomForestClassifier(n_estimators=50, max_features = 5, criterion='entropy')
RandomForest.fit(X_train, Y_train)

# Se hace la predicción
Y_predict_1   = RandomForest.predict(X_test)

# Test score (Precisión)
score_RandomForest = RandomForest.score(X_test, Y_test)
print(score_RandomForest)

"""### Se obtiene la matriz de confusión"""

# Matriz de confusión
from sklearn.metrics import confusion_matrix

CM_1 = confusion_matrix(Y_test, Y_predict_1)
f, ax = plt.subplots(figsize=(5,5))
sns.heatmap(CM_1, annot=True, linewidth=0.7, linecolor='cyan', fmt='g', ax=ax, cmap="YlGnBu")
plt.title('Matriz de confusión para Random Forest Classification')
plt.xlabel('Y predict')
plt.ylabel('Y test')
plt.show() 

print('Matriz de confusión\n\n', CM_1)

print('\nVerdadero Positivo = ', CM_1[0,0])

print('\nVerdadero Negativo = ', CM_1[1,1])

print('\nFalso Positivo = ', CM_1[0,1])

print('\nFalso Negativo = ', CM_1[1,0])

Accuracy_1 = (CM_1[0,0] + CM_1[1,1])/(CM_1[0,0] + CM_1[1,1] + CM_1[0,1] + CM_1[1,0]) 
Accuracy_1

"""### Se procederá a hacer el diagnóstico de la Varianza y Sesgo"""

# Varianza
Varianza = np.var(Y_predict_1)
Varianza

# Sesgo 
SSE = np.mean((np.mean(Y_predict_1) - Y)** 2) 
Bias = SSE - Varianza  
Bias

Error_Total = Bias + Varianza  
Error_Total

"""**Se observa que se tiene un sesgo muy bajo y una varianza baja. Respecto a la varianza, eso significa que no existe una gran dispersión con los datos, por otro lado el sesgo que obtenemos es muy bajo, lo que indica que se adapta muy bien a los datos. A continuación encontraremos los mejores hiperparámetros posibles para mejorar nuestro modelo, teniendo en cuenta la relación del sesgo-varianza para tener el mejor resultado posible **

### Cross-Validation
"""

from sklearn.model_selection import cross_val_score
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import StratifiedKFold 


pipeline = make_pipeline(StandardScaler(), RandomForest) # Se crea un pipeline

strtfdKFold = StratifiedKFold(n_splits=5)
kfold = strtfdKFold.split(X_train, Y_train)
scores = []

for k, (train, test) in enumerate(kfold):
    pipeline.fit(X_train.iloc[train, :], Y_train.iloc[train])
    score = pipeline.score(X_train.iloc[test, :], Y_train.iloc[test])
    scores.append(score)
    print('Fold: %2d, Training/Test Distribución Dividida: %s, Precisión: %.3f' % (k+1, np.bincount(Y_train.iloc[train]), score))
 
print('\n\nPrecisión del Cross-Validation: %.3f +/- %.3f' %(np.mean(scores), np.std(scores)))

"""### Se busca aumentar el score por medio de los hyperparameters y obtener valores balanceados entre la varianza y el sesgo

Se analizó haciendo uso de varias estimaciones, se imprimirá una tabla con las precisiones más altas obtenidas, junto a sus respectivos hiperparámetros.
"""

from sklearn.model_selection import ParameterGrid

# Grid de hiperparámetros evaluados
# ==============================================================================
param_grid = ParameterGrid(
                {'n_estimators': [150],
                 'max_features': [5, 7, 9],
                 'max_depth'   : [None, 3, 10, 20],
                 'criterion'   : ['gini', 'entropy']
                }
            )

# Loop para ajustar un modelo con cada combinación de hiperparámetros
# ==============================================================================
resultados = {'params': [], 'oob_accuracy': []}

for params in param_grid:
    
    modelo = RandomForestClassifier(
                oob_score    = True,
                n_jobs       = -1,
                random_state = 123,
                ** params
             )
    
    modelo.fit(X_train, Y_train)
    
    resultados['params'].append(params)
    resultados['oob_accuracy'].append(modelo.oob_score_)
    print(f"Modelo: {params} \u2713") 

    # Resultados
# ==============================================================================
resultados = pd.DataFrame(resultados)
resultados = pd.concat([resultados, resultados['params'].apply(pd.Series)], axis=1)
resultados = resultados.sort_values('oob_accuracy', ascending=False)
resultados = resultados.drop(columns = 'params')
resultados.head(4)

# Mejores hiperparámetros por out-of-bag error
# ==============================================================================
print("--------------------------------------------------")
print("Mejores hiperparámetros encontrados (oob-accuracy)")
print("--------------------------------------------------")
print(resultados.iloc[0,0], ":", resultados.iloc[0,:]['oob_accuracy'], "accuracy")

"""### Los resultados que se obtuvieron fueron los siguientes. 
El mejor Score fue de 0.859641, n_estimators=150, max_features = 9 y criterion='gini'
"""

#Best Params:  {n_estimators=150, max_features = 9, criterion='gini'} 

RandomForest_T = RandomForestClassifier(n_estimators=150, max_features = 9, criterion='gini')
RandomForest_T.fit(X_train, Y_train)

# Se hace la predicción
Y_predict_2 = RandomForest_T.predict(X_test)  

# Test score (Precisión)
score_RandomForest_2 = RandomForest_T.score(X_test, Y_test)
print(score_RandomForest_2)

# Varianza
Varianza_2 = np.var(Y_predict_2)
Varianza_2

# Sesgo 
SSE_2 = np.mean((np.mean(Y_predict_2) - Y)** 2) 
Bias_2 = SSE - Varianza_2 
Bias_2

CM_2 = confusion_matrix(Y_test, Y_predict_2)
f, ax = plt.subplots(figsize=(5,5))
sns.heatmap(CM_2, annot=True, linewidth=0.7, linecolor='cyan', fmt='g', ax=ax, cmap="YlGnBu")
plt.title('Matriz de confusión para Random Forest Classification')
plt.xlabel('Y predict')
plt.ylabel('Y test')
plt.show() 

print('Matriz de confusión\n\n', CM_2)

print('\nVerdadero Positivo = ', CM_2[0,0])

print('\nVerdadero Negativo = ', CM_2[1,1])

print('\nFalso Positivo = ', CM_2[0,1])

print('\nFalso Negativo = ', CM_2[1,0])

Accuracy_2 = (CM_2[0,0] + CM_2[1,1])/(CM_2[0,0] + CM_2[1,1] + CM_2[0,1] + CM_2[1,0]) 
Accuracy_2

"""### Se obtiene el porcentaje de mejora, entre los dos modelos una vez obtenido la mejora"""

print('Se obtuvo una mejora de {:0.2f}%.'.format( 100 * (Accuracy_2 - Accuracy_1) / Accuracy_1))

"""### Se añade una tabla de comparación para contrastar los resultados."""

Tabla = {'n_estimators':[150, 50] 
         , 'max_features': [9, 5] 
         , 'criterion': ['gini', 'entropy']
         , 'score': [0.8596413548815586, 0.8553021917201683]} 

pd.DataFrame(Tabla)