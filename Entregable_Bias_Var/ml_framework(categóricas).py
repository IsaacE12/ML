# -*- coding: utf-8 -*-
"""ML_Framework(Categóricas).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XfU6FI83BX2wBtD3Fj8qw4malg-bRvLf

### Uso de framework de ML para la implementación de una solución en un dataset de variables categóricas

Primeramente importamos las librerías necesarias para la implementación del modelo
"""

# Commented out IPython magic to ensure Python compatibility.
# Análisis de datos
import pandas as pd
import numpy as np
import random as rnd  


# Visualización 
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

url = 'https://raw.githubusercontent.com/IsaacE12/ML/master/Entregable_Bias_Var/weatherAUS.csv'
df = pd.read_csv(url) 
df.shape  
df.head

"""Quitamos las columnas que son innecesarias para nuestra predicción"""

data = df.drop(columns=['Evaporation','Sunshine','Cloud3pm','Cloud9am','Date','Location']) 
data = data.dropna(how='any') 
data 
print(data.shape)

"""Se remplazan los "No" y los "Si" en las variables de RainToday y RainTomorrow"""

data['RainToday'].replace({'No':0, 'Yes':1}, inplace = True) 
data['RainTomorrow'].replace({'No':0, 'Yes':1}, inplace = True)

"""Se hace uso de las variables dummy's para el reordenamiento de las variables categóricas"""

Categoricas = ['WindGustDir', 'WindDir3pm', 'WindDir9am']
dff = pd.get_dummies(data, columns=Categoricas)  
print(dff.shape)
dff.head()

"""### Se obtiene la matriz de correlación y se eliminan las variables que tienen menos de 0.5 de correlación respecto a la variable que nos interesa"""

# Calculate the correlation matrix
corr = dff.corr()
corr_1 = pd.DataFrame(abs(corr['RainTomorrow']),columns = ['RainTomorrow'])
nonvals = corr_1.loc[corr_1['RainTomorrow'] < 0.005]
print('Var correlation < 0.5%',nonvals)
nonvals = list(nonvals.index.values)

from sklearn.model_selection import train_test_split
Y = dff['RainTomorrow']
X = dff.drop(columns=['RainTomorrow']) 
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=5)

"""### Se aplica la clasificación de RandomForest"""

# Se importa la librería y se definde el model
from sklearn.ensemble import RandomForestClassifier  
RandomForest = RandomForestClassifier(n_estimators=50,random_state=9,n_jobs=-1)
RandomForest.fit(X_train, Y_train)

# Se hace la predicción
Y_predict_1   = RandomForest.predict(X_test)

# Test score (Precisión)
score_RandomForest = RandomForest.score(X_test, Y_test)
print(score_RandomForest)

"""### Se obtiene la matriz de confusión"""

# Matriz de confusión
from sklearn.metrics import confusion_matrix

CM_1 = confusion_matrix(Y_test, Y_predict_1)
f, ax = plt.subplots(figsize=(5,5))
sns.heatmap(CM_1, annot=True, linewidth=0.7, linecolor='cyan', fmt='g', ax=ax, cmap="YlGnBu")
plt.title('Matriz de confusión para Random Forest Classification')
plt.xlabel('Y predict')
plt.ylabel('Y test')
plt.show() 

print('Matriz de confusión\n\n', CM_1)

print('\nVerdadero Positivo = ', CM_1[0,0])

print('\nVerdadero Negativo = ', CM_1[1,1])

print('\nFalso Positivo = ', CM_1[0,1])

print('\nFalso Negativo = ', CM_1[1,0])

Accuracy_1 = (CM_1[0,0] + CM_1[1,1])/(CM_1[0,0] + CM_1[1,1] + CM_1[0,1] + CM_1[1,0]) 
Accuracy_1

"""### Se procederá a hacer el diagnóstico de la Varianza y Sesgo"""

# Varianza
Varianza = np.var(Y_predict_1)
Varianza

# Sesgo 
SSE = np.mean((np.mean(Y_predict_1) - Y)** 2) 
Bias = SSE - Varianza 
Bias

Error_Total = Bias + Varianza  
Error_Total

"""**Se observa que se tiene un sesgo muy bajo y una varianza baja. Respecto a la varianza, eso significa que no existe una gran dispersión con los datos, por otro lado el sesgo que obtenemos es muy bajo, lo que indica que se adapta muy bien a los datos. A continuación encontraremos los mejores hiperparámetros posibles para mejorar nuestro modelo, teniendo en cuenta la relación del sesgo-varianza para tener el mejor resultado posible **

### Se busca aumentar el score por medio de los hyperparameters y obtener valores balanceados entre la varianza y el sesgo
"""

# Este fue el código que nos permitió obtener los hiperparámetros, sin embargo, lo comenté porque toma 2 hrs en encontrar los resultados, es muy tardado.

"""
from sklearn.model_selection import GridSearchCV
clf = RandomForestClassifier()

param_grid = {
    'n_estimators': list(range(1,220, 20)),
    'max_depth': list(range(1,220, 20))
}

# Perform grid search on n_estimators and max_depth
gridsearch = GridSearchCV(estimator = clf, param_grid=param_grid, verbose=10, scoring='accuracy')
gridsearch.fit(X_train,Y_train)

print('Best Score: ', gridsearch.best_score_)
print('Best Params: ', gridsearch.best_params_) """

"""### Los resultados que se obtuvieron fueron los siguientes. 
El mejor Score fue de 0.8550, max_depth = 161 y n_estimator = 201
"""

#Best_Score = 0.8550033207881336 
#Best Params:  {'max_depth': 161, 'n_estimators': 201} 

RandomForest_T = RandomForestClassifier(n_estimators=201, max_depth = 161,random_state=9,n_jobs=-1)
RandomForest_T.fit(X_train, Y_train)

# Se hace la predicción
Y_predict_2 = RandomForest_T.predict(X_test)  

# Test score (Precisión)
score_RandomForest_2 = RandomForest_T.score(X_test, Y_test)
print(score_RandomForest_2)

# Test score
score_RandomForest_T = RandomForest_T.score(X_test, Y_test)
print(score_RandomForest_T)

# Varianza
Varianza_2 = np.var(Y_predict_2)
Varianza_2

# Sesgo 
SSE_2 = np.mean((np.mean(Y_predict_2) - Y)** 2) 
Bias_2 = SSE - Varianza_2 
Bias_2

CM_2 = confusion_matrix(Y_test, Y_predict_2)
f, ax = plt.subplots(figsize=(5,5))
sns.heatmap(CM_2, annot=True, linewidth=0.7, linecolor='cyan', fmt='g', ax=ax, cmap="YlGnBu")
plt.title('Matriz de confusión para Random Forest Classification')
plt.xlabel('Y predict')
plt.ylabel('Y test')
plt.show() 

print('Matriz de confusión\n\n', CM_2)

print('\nVerdadero Positivo = ', CM_2[0,0])

print('\nVerdadero Negativo = ', CM_2[1,1])

print('\nFalso Positivo = ', CM_2[0,1])

print('\nFalso Negativo = ', CM_2[1,0])

Accuracy_2 = (CM_2[0,0] + CM_2[1,1])/(CM_2[0,0] + CM_2[1,1] + CM_2[0,1] + CM_2[1,0]) 
Accuracy_2

"""### Se obtiene el porcentaje de mejora, entre los dos modelos una vez obtenido la mejora"""

print('Se obtuvo una mejora de {:0.2f}%.'.format( 100 * (Accuracy_2 - Accuracy_1) / Accuracy_1))