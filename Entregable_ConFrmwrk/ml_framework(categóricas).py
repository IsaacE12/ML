# -*- coding: utf-8 -*-
"""ML_Framework(Categóricas).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19SJXYmTAzup0d4iLNk7xEkKtP08InQ_e

### Uso de framework de ML para la implementación de una solución en un dataset de variables categóricas

Primeramente importamos las librerías necesarias para la implementación del modelo
"""

# Commented out IPython magic to ensure Python compatibility.
# Análisis de datos
import pandas as pd
import numpy as np
import random as rnd  


# Visualización 
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

url = 'https://raw.githubusercontent.com/IsaacE12/ML/master/Entregable_Bias_Var/weatherAUS.csv'
df = pd.read_csv(url) 
df.shape  
df.head

"""Quitamos las columnas que son innecesarias para nuestra predicción"""

data = df.drop(columns=['Evaporation','Sunshine','Cloud3pm','Cloud9am','Date','Location']) 
data = data.dropna(how='any') 
data 
print(data.shape)

"""Se remplazan los "No" y los "Si" en las variables de RainToday y RainTomorrow"""

data['RainToday'].replace({'No':0, 'Yes':1}, inplace = True) 
data['RainTomorrow'].replace({'No':0, 'Yes':1}, inplace = True)

"""Se hace uso de las variables dummy's para el reordenamiento de las variables categóricas"""

Categoricas = ['WindGustDir', 'WindDir3pm', 'WindDir9am']
dff = pd.get_dummies(data, columns=Categoricas)  
print(dff.shape)
dff.head()

"""### Se obtiene la matriz de correlación y se eliminan las variables que tienen menos de 0.5 de correlación respecto a la variable que nos interesa"""

# Calculate the correlation matrix
corr = dff.corr()
corr_1 = pd.DataFrame(abs(corr['RainTomorrow']),columns = ['RainTomorrow'])
nonvals = corr_1.loc[corr_1['RainTomorrow'] < 0.005]
print('Var correlation < 0.5%',nonvals)
nonvals = list(nonvals.index.values)

from sklearn.model_selection import train_test_split
Y = dff['RainTomorrow']
X = dff.drop(columns=['RainTomorrow']) 
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=5)

"""### Se aplica la clasificación de RandomForest"""

# Se importa la librería y se definde el model
from sklearn.ensemble import RandomForestClassifier  
RandomForest = RandomForestClassifier(n_estimators=50,random_state=9,n_jobs=-1)
RandomForest.fit(X_train, Y_train)

# Se hace la predicción
Y_predict_1   = RandomForest.predict(X_test)

# Test score (Precisión)
score_RandomForest = RandomForest.score(X_test, Y_test)
print(score_RandomForest)

"""### Se obtiene la matriz de confusión"""

# Matriz de confusión
from sklearn.metrics import confusion_matrix

CM_1 = confusion_matrix(Y_test, Y_predict_1)
f, ax = plt.subplots(figsize=(5,5))
sns.heatmap(CM_1, annot=True, linewidth=0.7, linecolor='cyan', fmt='g', ax=ax, cmap="YlGnBu")
plt.title('Matriz de confusión para Random Forest Classification')
plt.xlabel('Y predict')
plt.ylabel('Y test')
plt.show() 

print('Matriz de confusión\n\n', CM_1)

print('\nVerdadero Positivo = ', CM_1[0,0])

print('\nVerdadero Negativo = ', CM_1[1,1])

print('\nFalso Positivo = ', CM_1[0,1])

print('\nFalso Negativo = ', CM_1[1,0])

Accuracy_1 = (CM_1[0,0] + CM_1[1,1])/(CM_1[0,0] + CM_1[1,1] + CM_1[0,1] + CM_1[1,0]) 
Accuracy_1

from sklearn import metrics
mae = metrics.mean_absolute_error(Y_test, Y_predict_1)
mse = metrics.mean_squared_error(Y_test, Y_predict_1)   

print("Error cuadrático medio de" ,mse)

print("Error absoluto medio de" ,mae)

# Commented out IPython magic to ensure Python compatibility.

from google.colab import drive
drive.mount('/content/gdrive')
# %cd "/content/gdrive/MyDrive/Colab Notebooks"
!ls 
!sudo apt-get install texlive-xetex texlive-fonts-recommended texlive-plain-generic  
!jupyter nbconvert --to pdf 'ML_Framework(Categóricas).ipynb'